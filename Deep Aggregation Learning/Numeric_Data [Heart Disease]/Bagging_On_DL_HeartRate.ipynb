{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "danish-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "lr = 0.3\n",
    "from sklearn import preprocessing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix   \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading csv files\n",
    "df =  pd.read_csv('heart.dat', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "humanitarian-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2      3      4    5    6      7    8    9    10   11   12  \\\n",
       "0    70.0  1.0  4.0  130.0  322.0  0.0  2.0  109.0  0.0  2.4  2.0  3.0  3.0   \n",
       "1    67.0  0.0  3.0  115.0  564.0  0.0  2.0  160.0  0.0  1.6  2.0  0.0  7.0   \n",
       "2    57.0  1.0  2.0  124.0  261.0  0.0  0.0  141.0  0.0  0.3  1.0  0.0  7.0   \n",
       "3    64.0  1.0  4.0  128.0  263.0  0.0  0.0  105.0  1.0  0.2  2.0  1.0  7.0   \n",
       "4    74.0  0.0  2.0  120.0  269.0  0.0  2.0  121.0  1.0  0.2  1.0  1.0  3.0   \n",
       "..    ...  ...  ...    ...    ...  ...  ...    ...  ...  ...  ...  ...  ...   \n",
       "265  52.0  1.0  3.0  172.0  199.0  1.0  0.0  162.0  0.0  0.5  1.0  0.0  7.0   \n",
       "266  44.0  1.0  2.0  120.0  263.0  0.0  0.0  173.0  0.0  0.0  1.0  0.0  7.0   \n",
       "267  56.0  0.0  2.0  140.0  294.0  0.0  2.0  153.0  0.0  1.3  2.0  0.0  3.0   \n",
       "268  57.0  1.0  4.0  140.0  192.0  0.0  0.0  148.0  0.0  0.4  2.0  0.0  6.0   \n",
       "269  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   \n",
       "\n",
       "     13  \n",
       "0     2  \n",
       "1     1  \n",
       "2     2  \n",
       "3     1  \n",
       "4     1  \n",
       "..   ..  \n",
       "265   1  \n",
       "266   1  \n",
       "267   1  \n",
       "268   1  \n",
       "269   2  \n",
       "\n",
       "[270 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excess-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['age', 'sex', 'chest pain', 'resting blood pressure', 'serum cholestoral', 'fasting blood sugar', 'resting electrocardiographic', 'maximum heart rate achieved',' exercise induced angina', 'oldpeak',' the slope of the peak exercise ST segment', 'number of major vessels', 'tha', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yellow-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = column_name\n",
    "df = df.fillna(0)\n",
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hungarian-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "trans = StandardScaler()\n",
    "X = trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quiet-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.iloc[:, -1]\n",
    "label = label.map({1:0, 2:1})\n",
    "label = label.map({0:0, 1:1, 2:1, 3:1, 4:1})\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-skill",
   "metadata": {},
   "source": [
    "## Feature important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "theoretical-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_Imputed = X\n",
    "feature_names = [f'feature {i}' for i in range(X_Imputed.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_Imputed, label)\n",
    "importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "preliminary-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imprtance = pd.DataFrame(importances)\n",
    "index_top_n_Feature = df_imprtance.sort_values(by=df_imprtance.columns[0],ascending=False).iloc[:12,].index\n",
    "X_Imputed_df = pd.DataFrame(X_Imputed)\n",
    "X_Imputed_df = X_Imputed_df.iloc[:,index_top_n_Feature.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "running-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Imputed_df, label, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "variable-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow\n",
    "\n",
    "def training(X, y, iteration, epoch):\n",
    "    #iteration = iteration+1\n",
    "    # define the keras model\n",
    "    model_path = 'DL_model_Bagging_Numeric/model_'+str(iteration)+'.h5'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(248, input_dim=X.shape[-1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2,  activation = \"softmax\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    model.fit(X, y, \n",
    "              epochs=epoch,\n",
    "              batch_size=2000,\n",
    "              validation_split=0.25,\n",
    "              verbose=0,\n",
    "              #class_weight=class_weights, \n",
    "              callbacks = [LearningRateScheduler(lr_scheduler, verbose=0),\n",
    "                                    tensorflow.keras.callbacks.ModelCheckpoint(model_path,\n",
    "                                                                               monitor='val_loss',\n",
    "                                                                               save_best_only=True,\n",
    "                                                                               mode='min',\n",
    "                                                                               verbose=0)])\n",
    "    print(\"======================= Done for iteration \", iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-strap",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "technological-volleyball",
   "metadata": {},
   "source": [
    "## Device data into bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "clinical-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 50 == 0 and epoch:\n",
    "        lr = lr - lr*0.1\n",
    "        return lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "piano-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def model_Predict(X):\n",
    "    RM_predicted =[]\n",
    "    for i in range(0, num_Interation):\n",
    "        model = load_model('DL_model_Bagging_Numeric/model_'+str(i)+\".h5\")\n",
    "        RM_predicted.append(model.predict(X))        \n",
    "    return RM_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fifteen-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_real, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "    acc= (tp + tn)/(tp+tn+fp+fn)\n",
    "    pre= tp/(tp+fp)\n",
    "    Recall=  (tp)/(tp+fn)\n",
    "    spec= (tn)/(tn+fp)\n",
    "    F1score= (2*(tp)/(2*tp+fp+fn))\n",
    "    mcc= ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-default",
   "metadata": {},
   "source": [
    "## Running on Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-source",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)\n",
    "\n",
    "import timeit\n",
    "import tracemalloc\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# split 10 fold of undersampling\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "max_auc = 0.88\n",
    "for num_Interation in range(1, 50):\n",
    "    rsFile = \"Result_OverIteration_Bagging_Numeric/NumberOfBag_\"+str(num_Interation)+\".csv\"\n",
    "    f2=open(rsFile,\"w\")\n",
    "    f2.write('num_Interation, epoch, Time_train, Train_Peak_RAM, Time_predict, Peak_Time_prediction, thres, tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc, auc\\n')\n",
    "    for epoch in range(10, 500, 10):\n",
    "    \n",
    "        print(\"working on num_Interation: \" + str(num_Interation) + \"_with_epoch_\"+str(epoch))\n",
    "        \n",
    "        X_train_List=[]\n",
    "        y_train_List = []\n",
    "\n",
    "        for i in range(0, num_Interation):\n",
    "            X_over, y_over = undersample.fit_resample(X_train, y_train)\n",
    "            X_train_List.append(X_over.values)\n",
    "\n",
    "            y_over = to_categorical(y_over)\n",
    "            y_train_List.append(y_over)\n",
    "\n",
    "        X_train_List = np.array(X_train_List)\n",
    "        y_train_List = np.array(y_train_List)\n",
    "\n",
    "        X_train_List = np.array(X_train_List)\n",
    "        y_train_List = np.array(y_train_List)\n",
    "\n",
    "        \n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        tracemalloc.start()\n",
    "        \n",
    "        \n",
    "        for i in range(0, num_Interation):\n",
    "            training(X_train_List[i], y_train_List[i], i, epoch)\n",
    "\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        stop = timeit.default_timer()\n",
    "        Time_train=stop - start\n",
    "        Train_Peak_RAM = peak / 10**6\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        tracemalloc.start()\n",
    "        \n",
    "        predicted = model_Predict(X_test)\n",
    "        \n",
    "        stop = timeit.default_timer()\n",
    "        Time_predict=stop - start\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        Peak_Time_prediction = peak / 10**6\n",
    "        \n",
    "        result = np.array([[0]*predicted[i].shape[1]]*predicted[i].shape[0])\n",
    "\n",
    "        for i in range(0, num_Interation):\n",
    "            result = result+ predicted[i]\n",
    "        auc=roc_auc_score(y_test, result[:, 1]/num_Interation)\n",
    "        \n",
    "        thres = result.min()\n",
    "        while (thres <= result.max()):\n",
    "            thres = thres+result.max()/500\n",
    "            yhat = []\n",
    "            for i in range(len(result)):\n",
    "                if result[i][0]>thres:\n",
    "                    yhat.append(0)\n",
    "                else:\n",
    "                    yhat.append(1)\n",
    "\n",
    "            yhat = np.array(yhat)\n",
    "\n",
    "            tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc = conf_matrix(y_test, yhat)\n",
    "            f2.write(str(num_Interation)+\", \"+str(epoch)+\", \"+str(Time_train)+\", \"+str(Train_Peak_RAM)+\", \"+str(Time_predict)+\", \"+str(Peak_Time_prediction)+\", \"+str(thres)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(tp)+\", \"+str(acc)+\", \"+str(pre)+\", \"+str(Recall)+\", \"+str(spec)+\", \"+str(F1score)+\", \"+str(mcc)+\", \"+str(auc)+\"\\n\")\n",
    "\n",
    "\n",
    "    f2.close()\n",
    "    print('WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!')       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-intention",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
