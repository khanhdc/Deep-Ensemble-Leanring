{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "potential-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "\n",
    "import random\n",
    "# example of zoom image augmentation\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# example of loading the vgg16 model\n",
    "from tensorflow.keras.applications import ResNet50V2, DenseNet121\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "import tensorflow\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silent-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"..\\chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(main_path,\"train\")\n",
    "test_path=os.path.join(main_path,\"test\")\n",
    "val_path=os.path.join(main_path,\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_train_images = glob.glob(train_path+\"\\\\PNEUMONIA\\\\*.jpeg\")\n",
    "normal_train_images = glob.glob(train_path+\"\\\\NORMAL\\\\*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_test_images = glob.glob(test_path+\"\\\\PNEUMONIA\\\\*.jpeg\")\n",
    "normal_test_images = glob.glob(test_path+\"\\\\NORMAL\\\\*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addressed-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_val_images = glob.glob(val_path+\"\\\\PNEUMONIA\\\\*.jpeg\")\n",
    "normal_val_images = glob.glob(val_path+\"\\\\NORMAL\\\\*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "killing-collaboration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(normal_train_images))\n",
    "print(len(pneumonia_train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.concatenate([[0]*len(normal_train_images) , [1] *  len(pneumonia_train_images)]),columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-symbol",
   "metadata": {},
   "source": [
    "# Defining Image Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-johnston",
   "metadata": {},
   "source": [
    "## Load image into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "binary-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_train=[]\n",
    "pneumonia_trian =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "received-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1341/1341 [00:36<00:00, 37.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "for dirs in tqdm(normal_train_images):\n",
    "    img = cv2.imread(dirs)    \n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(img2gray, (200,200))\n",
    "    #print(resized.shape)\n",
    "    Normal_train.append(np.array(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "serious-festival",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3875/3875 [00:37<00:00, 102.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "for dirs in tqdm(pneumonia_train_images):\n",
    "    img = cv2.imread(dirs)    \n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(img2gray, (200,200))\n",
    "    #print(resized.shape)\n",
    "    pneumonia_trian.append(np.array(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "headed-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stretch-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_train_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-extra",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1341/1341 [00:00<00:00, 1343660.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0,len(Normal_train))):\n",
    "    #print(a.shape)\n",
    "    #print(Normal_train[i].shape)\n",
    "    Normal_train_array.append(Normal_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacterial-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1341/1341 [11:01<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "from tqdm import tqdm\n",
    "for dirs in tqdm(normal_train_images):\n",
    "    ind=ind+1\n",
    "    img = cv2.imread(dirs) \n",
    "    data = img_to_array(img)\n",
    "    samples = expand_dims(data, 0)\n",
    "    \n",
    "    if ind%2 ==0:\n",
    "        continue\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(zoom_range=[0.8,1.0])\n",
    "        it = datagen.flow(samples, batch_size=1)\n",
    "        for i in range(2):\n",
    "            batch = it.next()\n",
    "            image = batch[0].astype('uint8')\n",
    "            resized = cv2.resize(image, (200,200))\n",
    "            img2gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)\n",
    "            Normal_train_array.append(img2gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confirmed-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_train_array_X = np.array(Normal_train_array)\n",
    "Normal_train_array_y = [0]*len(Normal_train_array_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "separate-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_trian_array_X = np.array(pneumonia_trian)\n",
    "pneumonia_train_array_y = [1]*len(pneumonia_trian_array_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-placement",
   "metadata": {},
   "source": [
    "### Read testing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "breathing-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_test=[]\n",
    "pneumonia_test =[]\n",
    "Normal_test_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "boxed-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:04<00:00, 48.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "for dirs in tqdm(normal_test_images):\n",
    "    img = cv2.imread(dirs)    \n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(img2gray, (200,200))\n",
    "    #print(resized.shape)\n",
    "    Normal_test.append(np.array(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daily-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:03<00:00, 129.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "for dirs in tqdm(pneumonia_test_images):\n",
    "    img = cv2.imread(dirs)    \n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(img2gray, (200,200))\n",
    "    #print(resized.shape)\n",
    "    pneumonia_test.append(np.array(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "incoming-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:00<00:00, 234520.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0,len(Normal_test))):\n",
    "    #print(a.shape)\n",
    "    #print(Normal_train[i].shape)\n",
    "    Normal_test_array.append(Normal_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regulated-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_test_array_X = np.array(Normal_test_array)\n",
    "Normal_test_array_y = [0]*len(Normal_test_array_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "floral-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_test_array_X = np.array(pneumonia_test)\n",
    "pneumonia_test_array_y = [1]*len(pneumonia_test_array_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "loving-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((Normal_test_array_X, pneumonia_test_array_X), axis=0)\n",
    "y_test = np.concatenate((np.array(Normal_test_array_y), np.array(pneumonia_test_array_y)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-finder",
   "metadata": {},
   "source": [
    "# Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "joined-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 100 == 0 and epoch:\n",
    "        lr = lr - lr*0.1\n",
    "        return lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "considered-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, index, epoch):\n",
    "    # define the keras model\n",
    "    model_path = 'DL_model_Bagging/model_'+str(index)+'.h5'\n",
    "    \n",
    "    X = X.reshape(X.shape[0],X.shape[1], X.shape[2], 1)\n",
    "    \n",
    "    model = ResNet50V2(include_top=False, weights=None, input_tensor=Input(shape=((X.shape[1], X.shape[2], 1))))\n",
    "    \n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation = 'sigmoid')(x)\n",
    "    x = Dense(2, activation = \"sigmoid\")(x)\n",
    "    model = tensorflow.keras.Model(model.input, x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=epoch, batch_size=120, validation_split=0.2,verbose=1, \n",
    "                       callbacks = [LearningRateScheduler(lr_scheduler, verbose=0),\n",
    "                                    tensorflow.keras.callbacks.ModelCheckpoint(model_path,\n",
    "                                                                               monitor='val_loss',\n",
    "                                                                               save_best_only=True,\n",
    "                                                                               mode='min',\n",
    "                                                                               verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "going-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def conf_matrix(y_real, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "    acc= (tp + tn)/(tp+tn+fp+fn)\n",
    "    pre= tp/(tp+fp)\n",
    "    sen= (tp)/(tp+fn)\n",
    "    spec= (tn)/(tn+fp)\n",
    "    F1score= 2*(tp)/(2*tp+fp+fn)  \n",
    "    mcc= ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return tn, fp, fn, tp, acc, pre, sen, spec, F1score, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "appreciated-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "def one_hot(y):\n",
    "    return to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "greenhouse-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def model_Predict(X):\n",
    "    try:\n",
    "        del(model)\n",
    "    except:\n",
    "        print(\"Oops!  Nomodel to delete...\")\n",
    "    \n",
    "    X = X.reshape(X.shape[0],X.shape[1], X.shape[2], 1)\n",
    "    \n",
    "    RM_predicted =[]\n",
    "    for i in range(0, num_Interation):\n",
    "        model = load_model('DL_model_Bagging/model_'+str(i)+\".h5\")\n",
    "        RM_predicted.append(model.predict(X))\n",
    "    \n",
    "        \n",
    "    return RM_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-consumption",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# split 10 fold of undersampling\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "max_auc = 0.88\n",
    "for num_Interation in range(10, 50, 5):\n",
    "    rsFile = \"Result_OverIteration_Bagging_Numeric/Image/NumberOfBag_\"+str(num_Interation)+\".csv\"\n",
    "    f2=open(rsFile,\"w\")\n",
    "    f2.write('num_Interation, epoch, thres, tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc, auc\\n')\n",
    "    for epoch in (100, 500):\n",
    "        \n",
    "        \n",
    "        print(\"working on num_Interation: \"+str(num_Interation) +\"With epoch: \"+str(epoch) )\n",
    "        X_train_List=[]\n",
    "        y_train_List = []\n",
    "\n",
    "        #Generating the bags\n",
    "\n",
    "        for i in range(0, num_Interation):\n",
    "            #print(len(Normal_train_array)*1.3)\n",
    "            pneumonia = np.array(random.sample(pneumonia_trian, int(len(Normal_train_array)*1.41)))\n",
    "            normal = np.array(Normal_train_array)\n",
    "            X_train_List.append(np.concatenate((normal, pneumonia)))\n",
    "            y_train_List.append(np.concatenate((([0]*len(Normal_train_array_X), [1]*(len(Normal_train_array_X)*2)))))\n",
    "\n",
    "        X_train_List = np.array(X_train_List)\n",
    "        y_train_List = np.array(y_train_List)\n",
    "\n",
    "        X_train_List = np.array(X_train_List)\n",
    "        y_train_List = np.array(y_train_List)\n",
    "\n",
    "\n",
    "        ## Start training\n",
    "        for i in range(0, num_Interation):\n",
    "            training(X_train_List[i], to_categorical(y_train_List[i]) , i, epoch)\n",
    "\n",
    "        predicted = model_Predict(X_test)\n",
    "        result = np.array([[0]*predicted[i].shape[1]]*predicted[i].shape[0])\n",
    "\n",
    "        for i in range(0, num_Interation):\n",
    "            #print(result)\n",
    "            result = result+ predicted[i]\n",
    "            ##print('*=================')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #print(y_test)\n",
    "        #print(len(result[:, 1]))\n",
    "\n",
    "\n",
    "        auc=roc_auc_score(y_test, result[:, 1]/num_Interation)\n",
    "        #print(np.argmax(y_test, axis=1))\n",
    "        print('==========================================')\n",
    "        #print(result[:, 1]/num_Interation)\n",
    "        #print(result[:, 1].shape)\n",
    "\n",
    "        if max_auc <= auc:\n",
    "            max_auc = auc\n",
    "            print('======= auc =======: ', auc)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        print(\"result: \", result)\n",
    "        print(\"result[:, 1].min() : \", result[:, 1].min())\n",
    "        print(\"result[:, 1].max() : \", result[:, 1].max())\n",
    "        thres = result[:, 1].min()\n",
    "        while (thres <= result[:, 1].max()):\n",
    "        #for thres in range(1, 1001):\n",
    "            thres = thres+(result[:, 1].max()/500)\n",
    "            yhat = []\n",
    "            for i in range(len(result)):\n",
    "                if result[i][1]>thres:\n",
    "                    yhat.append(1)\n",
    "                else:\n",
    "                    yhat.append(0)\n",
    "\n",
    "            yhat = np.array(yhat)\n",
    "\n",
    "            tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc = conf_matrix(y_test, yhat)\n",
    "            #auc = roc_plot(np.argmax(y_test, axis=1), yhat)\n",
    "            f2.write(str(num_Interation)+\", \"+str(epoch)+\", \"+str(thres)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(tp)+\", \"+str(acc)+\", \"+str(pre)+\", \"+str(Recall)+\", \"+str(spec)+\", \"+str(F1score)+\", \"+str(mcc)+\", \"+str(auc)+\"\\n\")\n",
    "\n",
    "    \n",
    "    f2.close()\n",
    "    print('WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!')       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
