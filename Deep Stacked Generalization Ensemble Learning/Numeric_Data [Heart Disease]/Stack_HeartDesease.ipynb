{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opponent-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked generalization with neural net meta model on blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fiscal-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "assert len(gpu) == 1\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composite-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading csv files\n",
    "df =  pd.read_csv('heart.dat', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pleasant-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2      3      4    5    6      7    8    9    10   11   12  \\\n",
       "0    70.0  1.0  4.0  130.0  322.0  0.0  2.0  109.0  0.0  2.4  2.0  3.0  3.0   \n",
       "1    67.0  0.0  3.0  115.0  564.0  0.0  2.0  160.0  0.0  1.6  2.0  0.0  7.0   \n",
       "2    57.0  1.0  2.0  124.0  261.0  0.0  0.0  141.0  0.0  0.3  1.0  0.0  7.0   \n",
       "3    64.0  1.0  4.0  128.0  263.0  0.0  0.0  105.0  1.0  0.2  2.0  1.0  7.0   \n",
       "4    74.0  0.0  2.0  120.0  269.0  0.0  2.0  121.0  1.0  0.2  1.0  1.0  3.0   \n",
       "..    ...  ...  ...    ...    ...  ...  ...    ...  ...  ...  ...  ...  ...   \n",
       "265  52.0  1.0  3.0  172.0  199.0  1.0  0.0  162.0  0.0  0.5  1.0  0.0  7.0   \n",
       "266  44.0  1.0  2.0  120.0  263.0  0.0  0.0  173.0  0.0  0.0  1.0  0.0  7.0   \n",
       "267  56.0  0.0  2.0  140.0  294.0  0.0  2.0  153.0  0.0  1.3  2.0  0.0  3.0   \n",
       "268  57.0  1.0  4.0  140.0  192.0  0.0  0.0  148.0  0.0  0.4  2.0  0.0  6.0   \n",
       "269  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   \n",
       "\n",
       "     13  \n",
       "0     2  \n",
       "1     1  \n",
       "2     2  \n",
       "3     1  \n",
       "4     1  \n",
       "..   ..  \n",
       "265   1  \n",
       "266   1  \n",
       "267   1  \n",
       "268   1  \n",
       "269   2  \n",
       "\n",
       "[270 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greater-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "welsh-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "trans = StandardScaler()\n",
    "X = trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adequate-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.iloc[:, -1]\n",
    "label = label.map({1:0, 2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legal-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "returning-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop an mlp for blobs dataset\n",
    "from matplotlib import pyplot\n",
    "# generate 2d classification dataset\n",
    "X, y = X, label\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up exponential learning rate decay\n",
    "def lr_decay(epoch):  \n",
    "    initial_lr = 0.001    \n",
    "    lr = initial_lr * np.exp(-0.1 * epoch)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greek-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes for metric saving, model saving, and LR reduction\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_decay, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-companion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "respiratory-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy, filename, epoch):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(248, input_dim=X.shape[-1], activation='tanh'))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=epoch, verbose=0, batch_size=500, validation_split=0.2,\n",
    "              callbacks=[lr_scheduler,\n",
    "                         ModelCheckpoint(filename,\n",
    "                                   monitor='loss',\n",
    "                                   save_best_only=True,\n",
    "                                   mode='min',\n",
    "                                   verbose=0)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-teaching",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monetary-patch",
   "metadata": {},
   "source": [
    "## Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brown-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-input",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hollow-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 13) (81, 13)\n"
     ]
    }
   ],
   "source": [
    "# stacked generalization with neural net meta model on blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from numpy import argmax\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "    # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            # rename to avoid 'unique layer name' issue\n",
    "            layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "    # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = Dense(32, activation='relu')(merge)\n",
    "    hidden = Dense(16, activation='relu')(hidden)\n",
    "    output = Dense(2, activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "    # plot graph of ensemble\n",
    "    #plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "    # compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fit a stacked model\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "    # prepare input data\n",
    "    #filename = 'models/final.h5'\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # encode output data\n",
    "    inputy_enc = inputy #to_categorical(inputy)\n",
    "    print(inputy_enc.shape)\n",
    "    # fit model\n",
    "    model.fit(X, inputy_enc, epochs=100, verbose=0, batch_size=300)\n",
    "    #model = load_model(filename)\n",
    "    \n",
    "    \n",
    "# make a prediction with a stacked model\n",
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "    X = [inputX for _ in range(len(model.input))]\n",
    "    # make prediction\n",
    "    return model.predict(X, verbose=0)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "\n",
    "print(trainX.shape, testX.shape)\n",
    "# load all models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-market",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-capital",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-expression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-nomination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-press",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-compensation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-explorer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-contrary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-water",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-evidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "soviet-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Plot ROC\n",
    "def roc_plot(y_real, y_predict):    \n",
    "    from sklearn.metrics import roc_curve, auc    \n",
    "    fpr, tpr, thresholds = roc_curve(y_real, y_predict)\n",
    "    auc = auc(fpr, tpr)\n",
    "    #print('Auc: ',auc)\n",
    "    #lw = 2\n",
    "    #plt.figure(1)\n",
    "    #plt.plot([0, 1], [0, 1], 'k--')\n",
    "    #plt.plot(fpr, tpr, label='Sleep disorder (area = {:.3f})'.format(auc))\n",
    "    #plt.plot(fpr, tpr, label='RF (area = {:.3f})'.format(auc))\n",
    "    #plt.xlabel('False positive rate')\n",
    "    #plt.ylabel('True positive rate')\n",
    "    #plt.title('ROC curve')    \n",
    "    #plt.legend(loc='lower right')\n",
    "    #plt.show()\n",
    "    return auc\n",
    "    \n",
    "import math\n",
    "def conf_matrix(y_real, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "    #print('confusion matrix: (tn, fp, fn, tp)',tn, fp, fn, tp)\n",
    "    #print('acc= ', (tp + tn)/(tp+tn+fp+fn))\n",
    "    #print('pre= ', tp/(tp+fp))\n",
    "    #print('sen= Recall= ', (tp)/(tp+fn))\n",
    "    #print('spec= ', (tn)/(tn+fp))\n",
    "    #print('F1score= ', 2*(tp)/(2*tp+fp+fn))      \n",
    "    #print('mcc= ', ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    \n",
    "    \n",
    "    acc= (tp + tn)/(tp+tn+fp+fn)\n",
    "    pre= tp/(tp+fp)\n",
    "    Recall=  (tp)/(tp+fn)\n",
    "    spec= (tn)/(tn+fp)\n",
    "    F1score= (2*(tp)/(2*tp+fp+fn))\n",
    "    mcc= ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    \n",
    "    \n",
    "    return tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-terror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-license",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "starting-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tender-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wirking on  0\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "===================: \n",
      "======= AUC ==============:  0.9046717171717171\n",
      "=====AUC===AUC=====: \n",
      "===AUC========AUC==: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "===================: \n",
      "===================: \n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  1\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  2\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "===================: \n",
      "======= AUC ==============:  0.9027777777777778\n",
      "=====AUC===AUC=====: \n",
      "===AUC========AUC==: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "===================: \n",
      "===================: \n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  3\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "===================: \n",
      "======= AUC ==============:  0.9002525252525252\n",
      "=====AUC===AUC=====: \n",
      "===AUC========AUC==: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "===================: \n",
      "===================: \n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  4\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  5\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  6\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  7\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "===================: \n",
      "======= AUC ==============:  0.9002525252525253\n",
      "=====AUC===AUC=====: \n",
      "===AUC========AUC==: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "===================: \n",
      "===================: \n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  8\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "===================: \n",
      "======= AUC ==============:  0.9015151515151515\n",
      "=====AUC===AUC=====: \n",
      "===AUC========AUC==: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "=AUC===========AUC=: \n",
      "===================: \n",
      "===================: \n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n",
      "wirking on  9\n",
      ">Saved models/model_1.h5\n",
      ">Saved models/model_2.h5\n",
      ">Saved models/model_3.h5\n",
      ">Saved models/model_4.h5\n",
      ">Saved models/model_5.h5\n",
      ">loaded models/model_1.h5\n",
      ">loaded models/model_2.h5\n",
      ">loaded models/model_3.h5\n",
      ">loaded models/model_4.h5\n",
      ">loaded models/model_5.h5\n",
      "(189, 2)\n",
      "y_test.shape  (81,)\n",
      "==========================================\n",
      "WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from attention import Attention\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import timeit\n",
    "import tracemalloc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "# split 10 fold of undersampling\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "max_auc = 0.90\n",
    "for time in range(0, 10):\n",
    "    print(\"wirking on \", time)\n",
    "    rsFile = \"Result_OverIteration_Bagging_Numeric/NumberOfBag_10Time\"+str(time)+\".csv\"\n",
    "    f2=open(rsFile,\"w\")\n",
    "    f2.write('Time_train, Train_Peak_RAM, Time_predict, Peak_Time_prediction, thres, tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc, auc\\n')\n",
    "    for num_Interation in ([5]): #range(2, 10, 2):\n",
    "        for epoch in ([250]): # (100, 500):\n",
    "            #print(\"working on num_Interation: \" + str(num_Interation) + \"_with_epoch_\"+str(epoch))\n",
    "\n",
    "\n",
    "\n",
    "            # ============== Starting training\n",
    "            start = timeit.default_timer()\n",
    "            tracemalloc.start()\n",
    "\n",
    "            ## Start training\n",
    "            for i in range(0, num_Interation):\n",
    "                # save model\n",
    "                filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "                # fit model\n",
    "                model = fit_model(X_train, to_categorical(y_train), filename, epoch)\n",
    "                #model = fit_model(trainX, trainy)\n",
    "                #model.save(filename)\n",
    "                print('>Saved %s' % filename)\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            stop = timeit.default_timer()\n",
    "            Time_train=stop - start\n",
    "            Train_Peak_RAM = peak / 10**6\n",
    "            #print('traning time: ', Time_train)\n",
    "            #print('Peak_Time:', Train_Peak_RAM)\n",
    "\n",
    "\n",
    "            # ============== Starting predicting\n",
    "            members = load_all_models(num_Interation)\n",
    "            # define ensemble model\n",
    "            stacked_model = define_stacked_model(members)\n",
    "            #stacked_model.name = 'stacked_model_iter_'+str(num_Interation)+'_Epoc_'+str(epoch)\n",
    "            # fit stacked model on test dataset\n",
    "            fit_stacked_model(stacked_model, X_train, to_categorical(y_train))\n",
    "\n",
    "\n",
    "            start = timeit.default_timer()\n",
    "            tracemalloc.start()\n",
    "\n",
    "            predicted = predict_stacked_model(stacked_model, X_test)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            Time_predict=stop - start\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            Peak_Time_prediction = peak / 10**6\n",
    "\n",
    "\n",
    "            auc=roc_auc_score(y_test, predicted[:, 1])\n",
    "            print('y_test.shape ' ,y_test.shape)\n",
    "            print('==========================================')\n",
    "\n",
    "\n",
    "            if max_auc <= auc:\n",
    "                #max_auc = auc\n",
    "                print('===================: ')\n",
    "                print('======= AUC ==============: ', auc)\n",
    "                print('=====AUC===AUC=====: ')\n",
    "                print('===AUC========AUC==: ')\n",
    "                print('=AUC===========AUC=: ')\n",
    "                print('=AUC===========AUC=: ')\n",
    "                print('=AUC===========AUC=: ')\n",
    "                print('===================: ')\n",
    "                print('===================: ')\n",
    "\n",
    "\n",
    "\n",
    "            thres = predicted[:, 1].min()\n",
    "            while (thres <= predicted[:, 1].max()):\n",
    "                thres = thres+(predicted[:, 1].max()/500)\n",
    "                pred = []\n",
    "                for i in range(len(predicted)):\n",
    "                    if predicted[i][1]>thres:\n",
    "                        pred.append(1)\n",
    "                    else:\n",
    "                        pred.append(0)\n",
    "\n",
    "                pred = np.array(pred)      \n",
    "\n",
    "                tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc = conf_matrix(y_test, pred)\n",
    "                #auc = roc_plot(y_test, yhat)\n",
    "                f2.write(str(num_Interation)+\", \"+str(epoch)+\", \"+str(Time_train)+\", \"+str(Train_Peak_RAM)+\", \"+str(Time_predict)+\", \"+str(Peak_Time_prediction)+\", \"+str(thres)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(tp)+\", \"+str(acc)+\", \"+str(pre)+\", \"+str(Recall)+\", \"+str(spec)+\", \"+str(F1score)+\", \"+str(mcc)+\", \"+str(auc)+\"\\n\")\n",
    "\n",
    "            del(stacked_model)\n",
    "    f2.close()\n",
    "    print('WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!')       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
