{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specialized-reynolds",
   "metadata": {
    "id": "mature-smell"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow\n",
    "tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)\n",
    "import timeit\n",
    "import tracemalloc\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "lr = 0.3 # Learning rate for Gradient Boosting CLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spread-arrival",
   "metadata": {
    "id": "compound-belief"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading csv files\n",
    "df =  pd.read_csv('heart.dat', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sharing-membrane",
   "metadata": {
    "id": "warming-money"
   },
   "outputs": [],
   "source": [
    "num_Interation = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peripheral-entertainment",
   "metadata": {
    "id": "available-elder"
   },
   "outputs": [],
   "source": [
    "column_name = ['age', 'sex', 'chest pain', 'resting blood pressure', 'serum cholestoral', 'fasting blood sugar', 'resting electrocardiographic', 'maximum heart rate achieved',' exercise induced angina', 'oldpeak',' the slope of the peak exercise ST segment', 'number of major vessels', 'tha', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-burning",
   "metadata": {
    "id": "fitted-skill"
   },
   "outputs": [],
   "source": [
    "df.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thermal-quantity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "boxed-graphic",
    "outputId": "8fdd53d9-e345-46de-d811-97a571239241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain</th>\n",
       "      <th>resting blood pressure</th>\n",
       "      <th>serum cholestoral</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting electrocardiographic</th>\n",
       "      <th>maximum heart rate achieved</th>\n",
       "      <th>exercise induced angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>the slope of the peak exercise ST segment</th>\n",
       "      <th>number of major vessels</th>\n",
       "      <th>tha</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  chest pain  resting blood pressure  serum cholestoral  \\\n",
       "0    70.0  1.0         4.0                   130.0              322.0   \n",
       "1    67.0  0.0         3.0                   115.0              564.0   \n",
       "2    57.0  1.0         2.0                   124.0              261.0   \n",
       "3    64.0  1.0         4.0                   128.0              263.0   \n",
       "4    74.0  0.0         2.0                   120.0              269.0   \n",
       "..    ...  ...         ...                     ...                ...   \n",
       "265  52.0  1.0         3.0                   172.0              199.0   \n",
       "266  44.0  1.0         2.0                   120.0              263.0   \n",
       "267  56.0  0.0         2.0                   140.0              294.0   \n",
       "268  57.0  1.0         4.0                   140.0              192.0   \n",
       "269  67.0  1.0         4.0                   160.0              286.0   \n",
       "\n",
       "     fasting blood sugar  resting electrocardiographic  \\\n",
       "0                    0.0                           2.0   \n",
       "1                    0.0                           2.0   \n",
       "2                    0.0                           0.0   \n",
       "3                    0.0                           0.0   \n",
       "4                    0.0                           2.0   \n",
       "..                   ...                           ...   \n",
       "265                  1.0                           0.0   \n",
       "266                  0.0                           0.0   \n",
       "267                  0.0                           2.0   \n",
       "268                  0.0                           0.0   \n",
       "269                  0.0                           2.0   \n",
       "\n",
       "     maximum heart rate achieved   exercise induced angina  oldpeak  \\\n",
       "0                          109.0                       0.0      2.4   \n",
       "1                          160.0                       0.0      1.6   \n",
       "2                          141.0                       0.0      0.3   \n",
       "3                          105.0                       1.0      0.2   \n",
       "4                          121.0                       1.0      0.2   \n",
       "..                           ...                       ...      ...   \n",
       "265                        162.0                       0.0      0.5   \n",
       "266                        173.0                       0.0      0.0   \n",
       "267                        153.0                       0.0      1.3   \n",
       "268                        148.0                       0.0      0.4   \n",
       "269                        108.0                       1.0      1.5   \n",
       "\n",
       "      the slope of the peak exercise ST segment  number of major vessels  tha  \\\n",
       "0                                           2.0                      3.0  3.0   \n",
       "1                                           2.0                      0.0  7.0   \n",
       "2                                           1.0                      0.0  7.0   \n",
       "3                                           2.0                      1.0  7.0   \n",
       "4                                           1.0                      1.0  3.0   \n",
       "..                                          ...                      ...  ...   \n",
       "265                                         1.0                      0.0  7.0   \n",
       "266                                         1.0                      0.0  7.0   \n",
       "267                                         2.0                      0.0  3.0   \n",
       "268                                         2.0                      0.0  6.0   \n",
       "269                                         2.0                      3.0  3.0   \n",
       "\n",
       "     label  \n",
       "0        2  \n",
       "1        1  \n",
       "2        2  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "265      1  \n",
       "266      1  \n",
       "267      1  \n",
       "268      1  \n",
       "269      2  \n",
       "\n",
       "[270 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "internal-interim",
   "metadata": {
    "id": "committed-subcommittee"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contemporary-source",
   "metadata": {
    "id": "collect-chest"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "trans = StandardScaler()\n",
    "X = trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "champion-clearance",
   "metadata": {
    "id": "corporate-gardening"
   },
   "outputs": [],
   "source": [
    "label = df.iloc[:, -1]\n",
    "label = label.map({1:0, 2:1})\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-keeping",
   "metadata": {
    "id": "attempted-bunny"
   },
   "source": [
    "## Feature important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "annual-assembly",
   "metadata": {
    "id": "backed-elite"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(X)\n",
    "X_Imputed  = imp_mean.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "innocent-waters",
   "metadata": {
    "id": "absolute-supervisor"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = [f'feature {i}' for i in range(X_Imputed.shape[1])]\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_Imputed, label)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "df_imprtance = pd.DataFrame(importances)\n",
    "index_top_n_Feature = df_imprtance.sort_values(by=df_imprtance.columns[0],ascending=False).iloc[:12,].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "devoted-jesus",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiscal-literature",
    "outputId": "f31a107e-ddf7-4257-e1d5-db59e1da7a70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  2,  7,  9, 11,  4,  0,  3, 10,  8,  1,  6], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_top_n_Feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "english-honolulu",
   "metadata": {
    "id": "imposed-custom"
   },
   "outputs": [],
   "source": [
    "X_Imputed_df = pd.DataFrame(X_Imputed)\n",
    "X_Imputed_df = X_Imputed_df.iloc[:,index_top_n_Feature.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "devoted-conflict",
   "metadata": {
    "id": "institutional-heating"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow\n",
    "\n",
    "def Res_model(X, y, index, epoch):\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(248, input_dim=X.shape[-1], activation='tanh'))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_absolute_error'])\n",
    "    model.fit(X, y, epochs=epoch, batch_size=5000, verbose = 0)\n",
    "    model.save('DL_model_Heart/model_'+str(index)+'.h5')\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instructional-lodge",
   "metadata": {
    "id": "charged-judges"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Imputed_df, label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "better-ridge",
   "metadata": {
    "id": "minute-timing"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "import math\n",
    "\n",
    "def conf_matrix(y_real, y_predict):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real, y_predict).ravel()\n",
    "    acc= (tp + tn)/(tp+tn+fp+fn)\n",
    "    pre= tp/(tp+fp)\n",
    "    Recall=  (tp)/(tp+fn)\n",
    "    spec= (tn)/(tn+fp)\n",
    "    F1score= (2*(tp)/(2*tp+fp+fn))\n",
    "    mcc= ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "instrumental-reverse",
   "metadata": {
    "id": "urban-theme"
   },
   "outputs": [],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def model_Predict(X, num_Interation):\n",
    "    result = np.array([0.5] * len(X))\n",
    "    for i in range(0, num_Interation):\n",
    "        model = load_model('DL_model_Heart/model_'+str(i)+\".h5\")\n",
    "        RM_predicted = model.predict(X)\n",
    "        result = result+lr*RM_predicted.reshape((len(X), ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-forth",
   "metadata": {
    "id": "MHr369yaxkZM"
   },
   "source": [
    "## Running on Multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-entrance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "alleged-teddy",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0104094f-ee40-4298-d5bf-0f351b926a20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num_Interation in range(2, 50):\n",
    "    rsFile = \"Result_OverIteration_Bagging_Numeric/NumberOfBag_\"+str(num_Interation)+\".csv\"\n",
    "    f2=open(rsFile,\"w\")\n",
    "    f2.write('num_Interation, epoch, Time_train, Train_Peak_RAM, Time_predict, Peak_Time_prediction, thres, tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc, auc\\n')\n",
    "    for epoch in range(10, 500, 10):\n",
    "    \n",
    "        print(\"working on num_Interation: \" + str(num_Interation) + \"_with_epoch_\"+str(epoch))\n",
    "        \n",
    "        Res = []\n",
    "        predicted_Base =  np.array([0.5] * len(X_train))\n",
    "        predicted = predicted_Base\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        tracemalloc.start()\n",
    "\n",
    "        ## Start training\n",
    "        for i in range(0, num_Interation):\n",
    "            Res = y_train-predicted\n",
    "            Predicted_Res = Res_model(X_train,Res, i, epoch)\n",
    "            New_predicted = predicted+ lr*Predicted_Res.reshape((Predicted_Res.shape[0],))\n",
    "            predicted = New_predicted\n",
    "\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        stop = timeit.default_timer()\n",
    "        Time_train=stop - start\n",
    "        Train_Peak_RAM = peak / 10**6\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        tracemalloc.start()\n",
    "        \n",
    "        predicted_test = model_Predict(X_test, num_Interation)\n",
    "        \n",
    "        stop = timeit.default_timer()\n",
    "        Time_predict=stop - start\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        Peak_Time_prediction = peak / 10**6\n",
    "        \n",
    "        \n",
    "        auc=roc_auc_score(y_test, predicted_test)\n",
    "        thres = predicted_test.min()\n",
    "        \n",
    "        while (thres <= predicted_test.max()):\n",
    "        #for thres in range(1, 1001):\n",
    "            thres = thres+(predicted_test.max()/500)\n",
    "            yhat = []\n",
    "            for i in range(len(predicted_test)):\n",
    "                if predicted_test[i]>thres:\n",
    "                    yhat.append(1)\n",
    "                else:\n",
    "                    yhat.append(0)\n",
    "\n",
    "            yhat = np.array(yhat)\n",
    "\n",
    "            tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc = conf_matrix(y_test, yhat)\n",
    "            f2.write(str(num_Interation)+\", \"+str(epoch)+\", \"+str(Time_train)+\", \"+str(Train_Peak_RAM)+\", \"+str(Time_predict)+\", \"+str(Peak_Time_prediction)+\", \"+str(thres)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(tp)+\", \"+str(acc)+\", \"+str(pre)+\", \"+str(Recall)+\", \"+str(spec)+\", \"+str(F1score)+\", \"+str(mcc)+\", \"+str(auc)+\"\\n\")\n",
    "\n",
    "\n",
    "    f2.close()\n",
    "    print('WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!')       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-beijing",
   "metadata": {
    "id": "sharp-setup"
   },
   "source": [
    "## Running on CLU 33, epoch 200 (the best hyper-parameter set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-bahrain",
   "metadata": {
    "id": "harmful-pride"
   },
   "outputs": [],
   "source": [
    "for time in range(0, 10):\n",
    "    rsFile = \"Result_OverIteration_Bagging_Numeric/NumberOfIteration\"+str(time)+\".csv\"\n",
    "    f2=open(rsFile,\"w\")\n",
    "    f2.write('num_Interation, epoch, Time_train, Train_Peak_RAM, Time_predict, Peak_Time_prediction, thres, tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc, auc\\n')\n",
    "    print(\"working on num_Interation: \" + str(time))\n",
    "    for num_Interation in ([33]):\n",
    "        for epoch in ([190]):\n",
    "            Res = []\n",
    "            predicted_Base =  np.array([0.5] * len(X_train))\n",
    "            predicted = predicted_Base\n",
    "            \n",
    "            start = timeit.default_timer()\n",
    "            tracemalloc.start()\n",
    "\n",
    "            ## Start training\n",
    "            for i in range(0, num_Interation):\n",
    "                Res = y_train-predicted\n",
    "                #print('Res: ',Res)\n",
    "                Predicted_Res = Res_model(X_train,Res, i, epoch)\n",
    "                New_predicted = predicted+ lr*Predicted_Res.reshape((Predicted_Res.shape[0],))\n",
    "                predicted = New_predicted\n",
    "\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            stop = timeit.default_timer()\n",
    "            Time_train=stop - start\n",
    "            Train_Peak_RAM = peak / 10**6\n",
    "            \n",
    "            \n",
    "            start = timeit.default_timer()\n",
    "            tracemalloc.start()\n",
    "\n",
    "            predicted_test = model_Predict(X_test, num_Interation)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            Time_predict=stop - start\n",
    "            current, peak = tracemalloc.get_traced_memory()\n",
    "            Peak_Time_prediction = peak / 10**6\n",
    "            \n",
    "            auc=roc_auc_score(y_test, predicted_test)\n",
    "\n",
    "            thres = predicted_test.min()\n",
    "            while (thres <= predicted_test.max()):\n",
    "            #for thres in range(1, 1001):\n",
    "                thres = thres+(predicted_test.max()/500)\n",
    "                yhat = []\n",
    "                for i in range(len(predicted_test)):\n",
    "                    if predicted_test[i]>thres:\n",
    "                        yhat.append(1)\n",
    "                    else:\n",
    "                        yhat.append(0)\n",
    "\n",
    "                yhat = np.array(yhat)\n",
    "\n",
    "                tn, fp, fn, tp, acc, pre, Recall, spec, F1score, mcc = conf_matrix(y_test, yhat)\n",
    "                f2.write(str(num_Interation)+\", \"+str(epoch)+\", \"+str(Time_train)+\", \"+str(Train_Peak_RAM)+\", \"+str(Time_predict)+\", \"+str(Peak_Time_prediction)+\", \"+str(thres)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(tp)+\", \"+str(acc)+\", \"+str(pre)+\", \"+str(Recall)+\", \"+str(spec)+\", \"+str(F1score)+\", \"+str(mcc)+\", \"+str(auc)+\"\\n\")\n",
    "\n",
    "\n",
    "    f2.close()\n",
    "    print('WRITING FILE SUCESSFULL ========!!!!!!!!!!!!!!!!!!!!!!')       "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "applicable-milan",
    "classified-stream"
   ],
   "name": "GBoostWithDL_HeartRate_eVALONePOCH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
